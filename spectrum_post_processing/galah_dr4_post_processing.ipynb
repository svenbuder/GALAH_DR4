{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94094d4",
   "metadata": {},
   "source": [
    "# GALAH DR4 Post Processing\n",
    "\n",
    "This script is used to follow up the spectroscopic analysis and post-process things like binarity etc.\n",
    "\n",
    "The code is maintained at\n",
    "https://github.com/svenbuder/GALAH_DR4\n",
    "and described at\n",
    "https://github.com/svenbuder/galah_dr4_paper\n",
    "\n",
    "Author(s): Sven Buder (ANU, ASTRO 3D)\n",
    "\n",
    "History:  \n",
    "220616: Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb141b1",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Preamble \n",
    "try:\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "    %config Completer.use_jedi = False\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "import astropy.constants as c\n",
    "import astropy.units as u\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr60 = Table.read('../observations/dr6.0_220701.fits')\n",
    "dr60['date'] = np.array([str(x)[:6] for x in dr60['sobject_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = np.unique(dr60['date'])\n",
    "# sobject_ids_per_date = []\n",
    "# for date in unique_dates:\n",
    "#     sobject_ids_per_date.append(len(dr60['date'][(dr60['date']==date) & np.isfinite(dr60['rv_com'])]))\n",
    "    \n",
    "# date_nr = Table()\n",
    "# date_nr['date'] = unique_dates\n",
    "# date_nr['nr'] = np.array(sobject_ids_per_date)\n",
    "# date_nr.sort(keys='nr',reverse=True)\n",
    "# date_nr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd735d",
   "metadata": {},
   "source": [
    "# Post process each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.argv[1] != '-f':\n",
    "    date = sys.argv[1]\n",
    "else:\n",
    "#     date = '140307'\n",
    "#     date = '131216'\n",
    "    date = '140305' # OmegaCen\n",
    "\n",
    "print('Post-Processing '+date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42074d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr60 = dr60[date == dr60['date']]\n",
    "dr60['gaia_id'][np.where(np.array(dr60['gaia_id']=='None'))[0]] = -1\n",
    "dr60.sort(keys='sobject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58893b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = Table.read('../spectrum_analysis/spectrum_masks/solar_spectrum_mask.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d48449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_sp_dictionary = dict()\n",
    "flag_sp_dictionary['emission']      = [1,'Emission in Halpha/Hbeta detected']\n",
    "flag_sp_dictionary['vsini_warn']    = [2,'Broadening (vsini) warning']\n",
    "flag_sp_dictionary['vmic_warn']     = [4,'Microturbulence (vmic) warning']\n",
    "flag_sp_dictionary['chi2_3sigma']   = [8,'chi square unusually low/high by 3 sigma']\n",
    "flag_sp_dictionary['is_sb2']        = [16,'Double line splitting detected (SB2)']\n",
    "flag_sp_dictionary['ccd_missing']   = [32,'Not all 4 CCDs available']\n",
    "flag_sp_dictionary['not_converged'] = [64,'Not converged within 4 iterations']\n",
    "flag_sp_dictionary['no_model']      = [128,'Extrapolating spectrum model']\n",
    "flag_sp_dictionary['no_results']    = [256,'No spectroscopic analysis results available']\n",
    "\n",
    "# a_file = open(\"final_flag_sp_dictionary.pkl\", \"wb\")\n",
    "# pickle.dump(flag_sp_dictionary,a_file)\n",
    "# a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2163f9b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def apply_final_flag_sp(results,spectra,final_table_row,has_results,emission_info):\n",
    "    intermediate_flag_sp = np.int(0)\n",
    "    \n",
    "    a_file = open(\"final_flag_sp_dictionary.pkl\", \"rb\")\n",
    "    flag_sp_dictionary = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "    \n",
    "    for reason in flag_sp_dictionary.keys():\n",
    "        \n",
    "        # Raise flag for 'no_results'\n",
    "        if reason == 'no_results':\n",
    "            if not has_results:\n",
    "                intermediate_flag_sp += flag_sp_dictionary['no_results'][0]\n",
    "                \n",
    "        if has_results:\n",
    "            \n",
    "            # Raise flag for 'chi2_3sigma':\n",
    "            # If the chi2_sp is more than 3 sigma above or below the expected value of median=0.82\n",
    "            if reason == 'chi2_3sigma':\n",
    "                if (final_table_row['chi2_sp'] < 0.57) | (final_table_row['chi2_sp'] > 1.4):\n",
    "                    intermediate_flag_sp += flag_sp_dictionary['chi2_3sigma'][0]\n",
    "\n",
    "            # Raise flag for 'is_sb2':\n",
    "            # If we have a significant and repeated detection of a velocity peak in the residual of sob-smod\n",
    "            if reason == 'is_sb2':\n",
    "                if np.isfinite(final_table_row['sb2_rv_16']):\n",
    "                    intermediate_flag_sp += flag_sp_dictionary['is_sb2'][0]\n",
    "\n",
    "            # Raise flag for 'vsini_warn':\n",
    "            if reason == 'vsini_warn':\n",
    "                if final_table_row['vsini'] > 25:\n",
    "                    intermediate_flag_sp += flag_sp_dictionary['vsini_warn'][0]\n",
    "\n",
    "            # Raise flag for 'vmic_warn':\n",
    "            if reason == 'vmic_warn':\n",
    "                if final_table_row['vmic'] < np.max([0.5,0.5 + 0.5*(final_table_row['teff']-6000.)/1000.]):\n",
    "                    intermediate_flag_sp += flag_sp_dictionary['vmic_warn'][0]\n",
    "\n",
    "            # Raise flag for 'emission':\n",
    "            if (reason == 'emission'):\n",
    "                if emission_info['any_emission']:\n",
    "                    intermediate_flag_sp += flag_sp_dictionary['emission'][0]\n",
    "\n",
    "            if reason == 'not_converged':\n",
    "                if((results['flag_sp_fit'][0] & 2) == 2):\n",
    "                    intermediate_flag_sp += flag_sp_dictionary['not_converged'][0]\n",
    "\n",
    "            if reason == 'ccd_missing':\n",
    "                if((results['flag_sp_fit'][0] & 4) == 4):\n",
    "                    intermediate_flag_sp += flag_sp_dictionary['ccd_missing'][0]\n",
    "\n",
    "            if reason == 'no_model':\n",
    "                if((results['flag_sp_fit'][0] & 1) == 1):\n",
    "                    intermediate_flag_sp += flag_sp_dictionary['no_model'][0]\n",
    "\n",
    "    return(intermediate_flag_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad56ba",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def create_final_dr40_table():\n",
    "    \n",
    "    empty_final_dr40_table = Table()\n",
    "    table_length = len(dr60['sobject_id'])\n",
    "    \n",
    "    # Identifiers\n",
    "    empty_final_dr40_table['sobject_id'] = np.array(dr60['sobject_id'], dtype=np.int64)\n",
    "    empty_final_dr40_table['tmass_id'] = np.array(dr60['2mass'], dtype=str)\n",
    "    empty_final_dr40_table['gaiadr3_source_id'] = np.array(dr60['gaia_id'], dtype=np.int64)\n",
    "\n",
    "    # Positions\n",
    "    empty_final_dr40_table['ra'] = np.array(dr60['ra'], dtype=np.float64)\n",
    "    empty_final_dr40_table['dec'] = np.array(dr60['dec'], dtype=np.float64)\n",
    "    \n",
    "    # Major Spectroscopic Results\n",
    "    empty_final_dr40_table['flag_sp'] = -np.ones(table_length, dtype=int)\n",
    "    for label in ['chi2_sp']:\n",
    "        empty_final_dr40_table[label] = np.zeros(table_length, dtype=np.float32); empty_final_dr40_table[label][:] = np.NaN\n",
    "    for label in ['model_name']:\n",
    "        empty_final_dr40_table[label] = np.array([' teff_logg_fe_h ' for x in range(table_length)])\n",
    "        \n",
    "    for label in ['rv','teff','logg','fe_h','vmic','vsini']:\n",
    "        empty_final_dr40_table[label] = np.zeros(table_length, dtype=np.float32); empty_final_dr40_table[label][:] = np.NaN\n",
    "        empty_final_dr40_table['e_'+label] = np.zeros(table_length, dtype=np.float32); empty_final_dr40_table['e_'+label][:] = np.NaN\n",
    "        if label == 'fe_h':\n",
    "            empty_final_dr40_table['flag_'+label] = -np.ones(table_length, dtype=int)\n",
    "        \n",
    "    # Elements\n",
    "    for element in [\n",
    "                'Li','C','N','O',\n",
    "                'Na','Mg','Al','Si',\n",
    "                'K','Ca','Sc','Ti','V','Cr','Mn','Co','Ni','Cu','Zn',\n",
    "                'Rb','Sr','Y','Zr','Mo','Ru',\n",
    "                'Ba','La','Ce','Nd','Sm','Eu'\n",
    "        ]:\n",
    "        empty_final_dr40_table[element.lower()+'_fe'] = np.zeros(table_length, dtype=np.float32); empty_final_dr40_table[element.lower()+'_fe'][:] = np.NaN\n",
    "        empty_final_dr40_table['e_'+element.lower()+'_fe'] = np.zeros(table_length, dtype=np.float32); empty_final_dr40_table['e_'+element.lower()+'_fe'][:] = np.NaN\n",
    "        empty_final_dr40_table['flag_'+element.lower()+'_fe'] = -np.ones(table_length, dtype=int)\n",
    "        \n",
    "    # Positions\n",
    "    empty_final_dr40_table['v_bary_eff'] = np.array(dr60['v_bary_eff'], dtype=np.float64)\n",
    "    #empty_final_dr40_table['red_rv_ccd'] = dr60['rv']\n",
    "    #empty_final_dr40_table['red_e_rv_ccd'] = dr60['e_rv']\n",
    "    empty_final_dr40_table['red_rv_com'] = np.array(dr60['rv_com'], dtype=np.float64)\n",
    "    empty_final_dr40_table['red_e_rv_com'] = np.array(dr60['e_rv_com'], dtype=np.float64)\n",
    "    empty_final_dr40_table['red_teff'] = np.array(dr60['teff_r'], dtype=np.float64)\n",
    "    empty_final_dr40_table['red_logg'] = np.array(dr60['logg_r'], dtype=np.float64)\n",
    "    empty_final_dr40_table['red_fe_h'] = np.array(dr60['fe_h_r'], dtype=np.float64)\n",
    "    empty_final_dr40_table['red_alpha_fe'] = np.array(dr60['alpha_fe_r'], dtype=np.float64)\n",
    "    empty_final_dr40_table['red_vmic'] = np.array(dr60['vmic_r'], dtype=np.float64)\n",
    "    empty_final_dr40_table['red_vbroad'] = np.array(dr60['vbroad_r'], dtype=np.float64)\n",
    "    empty_final_dr40_table['red_flag'] = np.array(dr60['e_rv_com'], dtype=np.int)\n",
    "\n",
    "    # Post processed analysis\n",
    "    for label in [\n",
    "        'sb2_rv_16','sb2_rv_50','sb2_rv_84',\n",
    "        'ew_h_beta','ew_h_alpha',\n",
    "        'ew_k_is', 'sigma_k_is', 'rv_k_is'\n",
    "        ]:\n",
    "        empty_final_dr40_table[label] = np.zeros(table_length, dtype=np.float32); empty_final_dr40_table[label][:] = np.NaN\n",
    "    for line in [5780.59,5797.19,6613.66]:\n",
    "        for label in ['ew_dib'+str(int(line)),'sigma_dib'+str(int(line)),'rv_dib'+str(int(line))]:\n",
    "            empty_final_dr40_table[label] = np.zeros(table_length, dtype=np.float32); empty_final_dr40_table[label][:] = np.NaN\n",
    "\n",
    "    # Additional information from spectrum_analysis\n",
    "    for ccd in [1,2,3,4]:\n",
    "        empty_final_dr40_table['snr_px_ccd'+str(ccd)] = dr60['snr'][:,ccd-1]\n",
    "    \n",
    "    return(empty_final_dr40_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f9005",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# We will assess line-splitting due to binarity with a few spectral lines\n",
    "spectral_lines_to_assess = [\n",
    "    4861.3230, # Hbeta\n",
    "    6562.7970, # Halpha\n",
    "    7771.9440, # O triplet\n",
    "    7774.1660, # O triplet\n",
    "    7775.3880, # O triplet\n",
    "    7691.5500, # Mg line\n",
    "    # Note that we do not use the K line here, because it was wrongly detecting interstellar as binary signatures\n",
    "    4890.7551, # Fe line\n",
    "    4891.4921, # Fe line\n",
    "    6643.6303, # Ni line\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de59773",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def identify_possible_RV_shifts(\n",
    "    spectra,\n",
    "    results,\n",
    "    minimum_significance_in_sigma = 5,\n",
    "    search_window_width_in_kms = 500,\n",
    "    search_window_center_in_kms = 0,\n",
    "    search_peak_width_in_kms = 50,\n",
    "    final = False,\n",
    "    debug = False,\n",
    "    ):\n",
    "        \n",
    "    possible_line_splitting_peaks = []\n",
    "    \n",
    "    # We have to make sure that the regions that are always masked (never fitted) are actually not used for estimating binarity\n",
    "    not_modelled = np.any(np.array([((spectra['wave'] >= mask_beginning) & (spectra['wave'] <= mask_end)) for (mask_beginning, mask_end) in zip(masks['mask_begin'],masks['mask_end'])]),axis=0)\n",
    "    \n",
    "    smod_for_binarity_test = np.array(spectra['smod'])\n",
    "    smod_for_binarity_test[not_modelled] = spectra['sob'][not_modelled]\n",
    "    \n",
    "    for line in spectral_lines_to_assess:\n",
    "        wave_km_s = ((spectra['wave']/line - 1)*c.c).to(u.km/u.s).value\n",
    "        within_rv_shift_km_s = np.abs(wave_km_s - search_window_center_in_kms) < 0.5*search_window_width_in_kms\n",
    "        \n",
    "\n",
    "        # We will work with the difference of observed and synthetic spectra\n",
    "        # To avoid low SNR to introduce issues, we will only allow differences above \n",
    "        # certain thresholds to be used\n",
    "        adjusted_flux_difference = (spectra['sob'][within_rv_shift_km_s] - smod_for_binarity_test[within_rv_shift_km_s])\n",
    "        adjusted_flux_difference[adjusted_flux_difference>-0.05] = 0.00\n",
    "        \n",
    "        # Let's interpolate the difference onto an equidistance velocity array\n",
    "        equidistant_velocity = np.arange(-0.5*search_window_width_in_kms+search_window_center_in_kms,0.5*search_window_width_in_kms+search_window_center_in_kms+0.1,0.5)\n",
    "        equidistant_flux_difference = np.interp(equidistant_velocity,wave_km_s[within_rv_shift_km_s],adjusted_flux_difference/spectra['uob'][within_rv_shift_km_s])\n",
    "        \n",
    "        if debug:\n",
    "            \n",
    "            f, gs = plt.subplots(1,2,figsize=(15,5))\n",
    "            \n",
    "            # Left panel: spectrum in AA in a left panel\n",
    "            # Right panel: flux difference (relative to noise) in km/s, including peaks that were identified\n",
    "            \n",
    "            ax = gs[0]\n",
    "            ax.set_xlabel(r'Shift from '+str(line)+'$\\,\\mathrm{\\AA}~/~\\mathrm{km\\,s^{-1}}$')\n",
    "            ax.set_ylabel('Flux / norm.')\n",
    "\n",
    "            ax.plot(\n",
    "                wave_km_s[within_rv_shift_km_s],\n",
    "                spectra['sob'][within_rv_shift_km_s],\n",
    "                c = 'k', label = 'Observation', lw = 1\n",
    "            )\n",
    "            ax.plot(\n",
    "                wave_km_s[within_rv_shift_km_s],\n",
    "                spectra['smod'][within_rv_shift_km_s],\n",
    "                c = 'r', label='Single Star Fit', lw = 1\n",
    "            )\n",
    "                            \n",
    "            ax = gs[1]\n",
    "            ax.set_xlabel(r'Shift from '+str(line)+'$\\,\\mathrm{\\AA}~/~\\mathrm{km\\,s^{-1}}$')\n",
    "            ax.set_ylabel(r'$\\Delta$Flux / $\\sigma$Flux')\n",
    "            ax.plot(\n",
    "                equidistant_velocity,\n",
    "                equidistant_flux_difference,\n",
    "                c = 'k', label='Residual', lw = 1\n",
    "            )\n",
    "        \n",
    "        # We will henceforth only consider flux difference above a specified sigma\n",
    "        equidistant_flux_difference[equidistant_flux_difference > -minimum_significance_in_sigma] = 0\n",
    "        equidistant_flux_difference[equidistant_flux_difference > -minimum_significance_in_sigma] = 0\n",
    "        \n",
    "        # Let's iteratively go through the spectrum and find peaks\n",
    "        # everytime, when we find a peak, we add it to *possible_line_splitting_peaks*\n",
    "        # and then set the values within the search window (e.g. +- 25km/s) of it to 0, until we cannot find any new peak\n",
    "        # For Halpha and Hbeta, we only do that once, because we expect the lines to cover more than the other lines\n",
    "\n",
    "        equidistant_flux_difference_to_search = equidistant_flux_difference\n",
    "        # To avoid badly fit lines (causing a peak at 0 km/s) to throw us off the path,\n",
    "        # We set the difference within 25 km/s (most stars line broadening should be below this threshold) to 0\n",
    "        equidistant_flux_difference_to_search[np.abs(equidistant_velocity) < 0.5*search_peak_width_in_kms] = 0\n",
    "        \n",
    "        # For Halpha and Hbeta, we actually go even broader, because we know their line cores and not fit well\n",
    "        if (not final) & (line in [4861.3230,6562.7970]):\n",
    "            equidistant_flux_difference_to_search[np.abs(equidistant_velocity) < 1*search_peak_width_in_kms] = 0\n",
    "        \n",
    "        while np.min(equidistant_flux_difference_to_search) < -minimum_significance_in_sigma:\n",
    "            \n",
    "            # find a new modus/peak\n",
    "            new_peak_index = np.argmin(equidistant_flux_difference_to_search)\n",
    "            \n",
    "            # add it to possible_line_splitting_peaks\n",
    "            possible_line_splitting_peaks.append(equidistant_velocity[np.argmin(equidistant_flux_difference)])\n",
    "                        \n",
    "            if debug:\n",
    "                ax.plot(\n",
    "                    equidistant_velocity,\n",
    "                    equidistant_flux_difference_to_search,\n",
    "                    label='_nolegend_', lw = 1\n",
    "                )\n",
    "            \n",
    "            # set flux to search in to 0 within search window of new peak\n",
    "            if line in [4861.3230,6562.7970]:\n",
    "                indices_within_search_window = np.abs(equidistant_velocity - equidistant_velocity[np.argmin(equidistant_flux_difference)]) < 1*search_peak_width_in_kms\n",
    "                equidistant_flux_difference_to_search[indices_within_search_window] = 0\n",
    "            else:\n",
    "                indices_within_search_window = np.abs(equidistant_velocity - equidistant_velocity[np.argmin(equidistant_flux_difference)]) < 0.5*search_peak_width_in_kms\n",
    "                equidistant_flux_difference_to_search[indices_within_search_window] = 0\n",
    "\n",
    "    if len(possible_line_splitting_peaks) >= 4:\n",
    "        hist = np.histogram(possible_line_splitting_peaks, bins=np.arange(-0.5*search_window_width_in_kms+search_window_center_in_kms,0.5*search_window_width_in_kms+search_window_center_in_kms+0.1,20))\n",
    "        if debug:\n",
    "            plt.figure()\n",
    "            plt.hist(possible_line_splitting_peaks, bins=np.arange(-0.5*search_window_width_in_kms+search_window_center_in_kms,0.5*search_window_width_in_kms+search_window_center_in_kms+0.1,20))\n",
    "            print(np.max(hist[0]))\n",
    "            \n",
    "        # Now let's decide which value to give back\n",
    "        if not final:\n",
    "            # Give back the mode\n",
    "            return([hist[1][np.argmax(hist[0])]])\n",
    "        else:\n",
    "            # Actually calculate percentiles\n",
    "            return(np.percentile(possible_line_splitting_peaks, q=[16,50,84]))\n",
    "    else:\n",
    "        return([np.NaN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20bf1c6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def assess_sb2_binarity(spectra,results,debug=False):\n",
    "    \"\"\"\n",
    "    Testing if the star is a spectroscopic binary with double line splitting\n",
    "    \"\"\"\n",
    "    sb2_rv_16 = np.NaN; sb2_rv_50 = np.NaN; sb2_rv_84 = np.NaN\n",
    "\n",
    "    # Let's first apply a broad search for the most narrow peak\n",
    "    most_common_peak = identify_possible_RV_shifts(\n",
    "        spectra = spectra,\n",
    "        results = results,\n",
    "        minimum_significance_in_sigma = 5,\n",
    "        search_window_width_in_kms = 500,\n",
    "        search_window_center_in_kms = 0,\n",
    "        search_peak_width_in_kms = 50,\n",
    "        final = False,\n",
    "        debug = debug\n",
    "    )\n",
    "    \n",
    "    if np.isfinite(most_common_peak[0]):\n",
    "\n",
    "        if debug:\n",
    "            print('Found common peak at ', most_common_peak[0])\n",
    "        \n",
    "        # Now off to a narrower analysis of the most common peak\n",
    "        binary_rv_shift_percentiles = identify_possible_RV_shifts(\n",
    "            spectra = spectra,\n",
    "            results = results,\n",
    "            minimum_significance_in_sigma = 5,\n",
    "            search_window_width_in_kms = 50,\n",
    "            search_window_center_in_kms = most_common_peak[0],\n",
    "            search_peak_width_in_kms = 50,\n",
    "            final = True,\n",
    "            debug = debug\n",
    "        )\n",
    "        if len(binary_rv_shift_percentiles) == 3:\n",
    "            p16,p50,p84 = binary_rv_shift_percentiles\n",
    "            if debug:\n",
    "                print('Returning 16/50/84th percentiles')\n",
    "                print('median +- sigma:')\n",
    "                print(r'$'+\"{:.1f}\".format(p50)+r'_{'+\"{:.1f}\".format(p50-p16)+r'}^{'+\"{:.1f}\".format(p84-p50)+'}~/~\\mathrm{km\\,s^{-1}}$')\n",
    "            return(p16,p50,p84)\n",
    "        else:\n",
    "            return([np.NaN,most_common_peak[0],np.NaN])\n",
    "            #print('No Peaks above required significance found for narrower search')\n",
    "    else:\n",
    "        return([np.NaN,np.NaN,np.NaN])\n",
    "        #print('No Peaks above required significance found')\n",
    "    \n",
    "    return(sb2_rv_16,sb2_rv_50,sb2_rv_84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58371f4b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def assess_binarity(spectra,results,debug=False):\n",
    "    \"\"\"\n",
    "    Based on the observed and synthetic spectra, this script analysis the residuals to identify common peaks\n",
    "    \"\"\"\n",
    "    \n",
    "    # First let's test if we have a spectroscopic binary type 2 (double-lined spectroscopic binary)\n",
    "    sb2_rv_16,sb2_rv_50,sb2_rv_84 = assess_sb2_binarity(spectra,results,debug)\n",
    "\n",
    "    return(sb2_rv_16,sb2_rv_50,sb2_rv_84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae536f22",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def assess_emission(spectra, debug=False):\n",
    "    \"\"\"\n",
    "    Examples sobject_ids:\n",
    "    131216001101315\n",
    "    \"\"\"\n",
    "\n",
    "    emission_indicators = dict()\n",
    "    emission_indicators['ew_h_beta'] = 4861.3230\n",
    "    emission_indicators['ew_h_alpha'] = 6562.7970   \n",
    "    \n",
    "    emission_info = dict()\n",
    "    \n",
    "    any_indicator_in_emission = 0\n",
    "    \n",
    "    if debug:\n",
    "        f, gs = plt.subplots(1,2,figsize=(7,3))\n",
    "\n",
    "    for index, line_name in enumerate(emission_indicators.keys()):\n",
    "        \n",
    "        line = emission_indicators[line_name]\n",
    "        \n",
    "        # Let's first test the criterium if the cores of the Balmer lines are in absorption\n",
    "        line_core = in_wavelength_bin = np.abs(spectra['wave'] - line) < 0.5\n",
    "        # now test if the observed flux of the line core is above the continuum flux of 1:\n",
    "        if np.median(spectra['sob'][line_core]) > 1:\n",
    "            any_indicator_in_emission = 1\n",
    "            wavelength_window = 5.0\n",
    "        else:\n",
    "            if line_name == 'ew_h_alpha':\n",
    "                wavelength_window = 1.25\n",
    "            if line_name == 'ew_h_beta':\n",
    "                wavelength_window = 0.75\n",
    "\n",
    "        in_wavelength_bin = np.abs(spectra['wave'] - line) < wavelength_window\n",
    "\n",
    "        equivalent_width = np.trapz(spectra['smod'][in_wavelength_bin] - spectra['sob'][in_wavelength_bin],x=spectra['wave'][in_wavelength_bin])\n",
    "        emission_info[line_name] = np.float32(equivalent_width)\n",
    "\n",
    "        if debug:\n",
    "            ax = gs[index]\n",
    "            ax.set_title(line_name)\n",
    "            ax.plot(\n",
    "                spectra['wave'][in_wavelength_bin],\n",
    "                spectra['sob'][in_wavelength_bin],\n",
    "                label = 'sob'\n",
    "            )\n",
    "            ax.plot(\n",
    "                spectra['wave'][in_wavelength_bin],\n",
    "                spectra['smod'][in_wavelength_bin],\n",
    "                label = 'smod'\n",
    "            )\n",
    "            ax.plot(\n",
    "                spectra['wave'][in_wavelength_bin],\n",
    "                spectra['smod'][in_wavelength_bin] - spectra['sob'][in_wavelength_bin],\n",
    "                label = 'smod-sob'\n",
    "            )\n",
    "            ax.legend()\n",
    "    if debug:\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    if any_indicator_in_emission:\n",
    "        emission_info['any_emission'] = True\n",
    "    else:\n",
    "        emission_info['any_emission'] = False\n",
    "        \n",
    "    return(emission_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e53e9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def assess_interstellar_k_absorption(spectra,debug=True):\n",
    "\n",
    "    around_k_line = np.abs(spectra['wave'] - 7698.9643) < 5\n",
    "    \n",
    "    if debug:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(\n",
    "            spectra['wave'][around_k_line],\n",
    "            spectra['sob'][around_k_line],\n",
    "            c='k'\n",
    "        )\n",
    "        plt.plot(\n",
    "            spectra['wave'][around_k_line],\n",
    "            spectra['smod'][around_k_line],\n",
    "            c='C0'\n",
    "        )\n",
    "\n",
    "    def gauss_func(x, a, x0, sigma):\n",
    "        return -np.abs(a)*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "\n",
    "    # Executing curve_fit on noisy data\n",
    "    popt, pcov = curve_fit(\n",
    "        gauss_func,\n",
    "        xdata = spectra['wave'][around_k_line],\n",
    "        ydata = spectra['sob'][around_k_line]-spectra['smod'][around_k_line],\n",
    "        p0 = [\n",
    "            1,\n",
    "            spectra['wave'][around_k_line][np.argmin(spectra['sob'][around_k_line]-spectra['smod'][around_k_line])],\n",
    "            0.2],\n",
    "        bounds = ((0,spectra['wave'][around_k_line][0],0.05),(100,spectra['wave'][around_k_line][-1],5))\n",
    "    )\n",
    "    \n",
    "    if debug:\n",
    "        plt.plot(\n",
    "            spectra['wave'][around_k_line],\n",
    "            spectra['smod'][around_k_line] + gauss_func(spectra['wave'][around_k_line], *popt),\n",
    "            c = 'C1', ls='dashed'\n",
    "        )\n",
    "        plt.axvline(popt[1])\n",
    "        plt.axvline(spectra['wave'][around_k_line][np.argmin(spectra['sob'][around_k_line]-spectra['smod'][around_k_line])])\n",
    "        plt.ylim(-0.1,1.2)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    if popt[2] < 0.1:\n",
    "        return(np.NaN, np.NaN, np.NaN)            \n",
    "    else:\n",
    "        return(\n",
    "            np.float32(np.abs(popt[0] * popt[2] * np.sqrt(2*np.pi))),\n",
    "            np.float32(np.abs(popt[2])),\n",
    "            np.float32(((popt[1] - 7698.9643)/7698.9643*c.c).to(u.km/u.s).value)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422b725",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def assess_dib_absorption(spectra, wavelength = 5780, debug=True):\n",
    "    \"\"\"\n",
    "    Based on results from Vogrinčič et al. (2022, in prep.)\n",
    "    \n",
    "    4726.40 ± 0.07 # 46\n",
    "    4762.57 ± 0.06 # 60\n",
    "    4855.25 ± 0.12 # 59\n",
    "    4859.89 ± 0.01 # 59\n",
    "    5705.21 ± 0.16 # 49\n",
    "    5747.62 ± 0.35 # 55\n",
    "    5780.59 ± 0.01 # 284\n",
    "    5784.78 ± 0.03 # 51\n",
    "    5797.19 ± 0.03 # 110\n",
    "    6496.67 ± 0.20 # 53\n",
    "    6530.17 ± 0.24 # 51\n",
    "    6589.97 ± 0.01 # 50\n",
    "    6613.66 ± 0.01 # 130\n",
    "    \"\"\"\n",
    "    \n",
    "    around_dib_line = np.abs(spectra['wave'] - wavelength) < 5\n",
    "    \n",
    "    if debug:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(\n",
    "            spectra['wave'][around_dib_line],\n",
    "            spectra['sob'][around_dib_line],\n",
    "            c='k'\n",
    "        )\n",
    "        plt.plot(\n",
    "            spectra['wave'][around_dib_line],\n",
    "            spectra['smod'][around_dib_line],\n",
    "            c='C0'\n",
    "        )\n",
    "\n",
    "    def gauss_func(x, a, x0, sigma):\n",
    "        return -np.abs(a)*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "\n",
    "    # Executing curve_fit on noisy data\n",
    "    popt, pcov = curve_fit(\n",
    "        gauss_func,\n",
    "        xdata = spectra['wave'][around_dib_line],\n",
    "        ydata = spectra['sob'][around_dib_line]-spectra['smod'][around_dib_line],\n",
    "        p0 = [1,wavelength,0.4],\n",
    "        bounds = ((0,spectra['wave'][around_dib_line][0],0.05),(100,spectra['wave'][around_dib_line][-1],5))\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        plt.plot(\n",
    "            spectra['wave'][around_dib_line],\n",
    "            spectra['smod'][around_dib_line] + gauss_func(spectra['wave'][around_dib_line], *popt),\n",
    "            c = 'C1', ls='dashed'\n",
    "        )\n",
    "        plt.ylim(-0.1,1.2)\n",
    "        if popt[2] > 0.1:\n",
    "            plt.show()\n",
    "            print(popt)\n",
    "        plt.close()\n",
    "        \n",
    "    if popt[2] < 0.1:\n",
    "        return(np.NaN, np.NaN, np.NaN)\n",
    "    else:\n",
    "        return(\n",
    "            np.float32(np.abs(popt[0] * popt[2] * np.sqrt(2*np.pi))),\n",
    "            np.float32(np.abs(popt[2])),\n",
    "            np.float32(((popt[1] - wavelength)/wavelength*c.c).to(u.km/u.s).value)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffcbc31",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Solar Abundances\n",
    "marcs2014_a_x_sun = dict()\n",
    "elements = [\n",
    " \"H\",  \"He\",  \"Li\",  \"Be\",   \"B\",   \"C\",   \"N\",   \"O\",   \"F\",  \"Ne\",\n",
    "\"Na\",  \"Mg\",  \"Al\",  \"Si\",   \"P\",   \"S\",  \"Cl\",  \"Ar\",   \"K\",  \"Ca\",\n",
    "\"Sc\",  \"Ti\",   \"V\",  \"Cr\",  \"Mn\",  \"Fe\",  \"Co\",  \"Ni\",  \"Cu\",  \"Zn\",\n",
    "\"Ga\",  \"Ge\",  \"As\",  \"Se\",  \"Br\",  \"Kr\",  \"Rb\",  \"Sr\",   \"Y\",  \"Zr\",\n",
    "\"Nb\",  \"Mo\",  \"Tc\",  \"Ru\",  \"Rh\",  \"Pd\",  \"Ag\",  \"Cd\",  \"In\",  \"Sn\",\n",
    "\"Sb\",  \"Te\",   \"I\",  \"Xe\",  \"Cs\",  \"Ba\",  \"La\",  \"Ce\",  \"Pr\",  \"Nd\",\n",
    "\"Pm\",  \"Sm\",  \"Eu\",  \"Gd\",  \"Tb\",  \"Dy\",  \"Ho\",  \"Er\",  \"Tm\",  \"Yb\",\n",
    "\"Lu\",  \"Hf\",  \"Ta\",   \"W\",  \"Re\",  \"Os\",  \"Ir\",  \"Pt\",  \"Au\",  \"Hg\",\n",
    "\"Tl\",  \"Pb\",  \"Bi\",  \"Po\",  \"At\",  \"Rn\",  \"Fr\",  \"Ra\",  \"Ac\",  \"Th\",\n",
    "\"Pa\",   \"U\",  \"Np\",  \"Pu\",  \"Am\",  \"Cm\",  \"Bk\",  \"Cs\",  \"Es\"\n",
    "]\n",
    "zeropoints = [\n",
    "12.00, 10.93,  1.05,  1.38,  2.70,  8.39,  7.78,  8.66,  4.56,  7.84,\n",
    " 6.17,  7.53,  6.37,  7.51,  5.36,  7.14,  5.50,  6.18,  5.08,  6.31,\n",
    " 3.17,  4.90,  4.00,  5.64,  5.39,  7.45,  4.92,  6.23,  4.21,  4.60,\n",
    " 2.88,  3.58,  2.29,  3.33,  2.56,  3.25,  2.60,  2.92,  2.21,  2.58,\n",
    " 1.42,  1.92, -8.00,  1.84,  1.12,  1.66,  0.94,  1.77,  1.60,  2.00,\n",
    " 1.00,  2.19,  1.51,  2.24,  1.07,  2.17,  1.13,  1.70,  0.58,  1.45,\n",
    "-8.00,  1.00,  0.52,  1.11,  0.28,  1.14,  0.51,  0.93,  0.00,  1.08,\n",
    " 0.06,  0.88, -0.17,  1.11,  0.23,  1.25,  1.38,  1.64,  1.01,  1.13,\n",
    " 0.90,  2.00,  0.65, -8.00, -8.00, -8.00, -8.00, -8.00, -8.00,  0.06,\n",
    "-8.00, -0.52, -8.00, -8.00, -8.00, -8.00, -8.00, -8.00, -8.00]\n",
    "for (element, zeropoint) in zip(elements, zeropoints):\n",
    "    marcs2014_a_x_sun[element] = zeropoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "galah_zeropoints = Table()\n",
    "galah_zeropoints['teff']  = [np.float32(5770.6)]\n",
    "galah_zeropoints['logg']  = [np.float32(4.339)]\n",
    "galah_zeropoints['A_Fe']  = [np.float32(7.45-0.070)]\n",
    "galah_zeropoints['vmic']  = [np.float32(1.07)]\n",
    "galah_zeropoints['vsini'] = [np.float32(5.7)]\n",
    "\n",
    "galah_zeropoints['A_Li'] = [np.float32(1.05+0.250)] # +0.543 VESTA, GAS07: 1.05, DR3: 1.05\n",
    "galah_zeropoints['A_C']  = [np.float32(8.39+0.035)] # VESTA, GAS07: 8.39, DR3: 8.45\n",
    "galah_zeropoints['A_N']  = [np.float32(7.78+0.150)]  # VESTA: 7.78+0.617, GAS07: 7.78, DR3:\n",
    "galah_zeropoints['A_O']  = [np.float32(8.66+0.070)] # -0.124 VESTA, GAS07: 8.66, DR3: 8.77\n",
    "galah_zeropoints['A_Na'] = [np.float32(6.17+0.204)] # VESTA, GAS07: 6.17, DR3: 6.06\n",
    "galah_zeropoints['A_Mg'] = [np.float32(7.53+0.069)] # +0.164 VESTA, GAS07: 7.53, DR3: 7.60\n",
    "galah_zeropoints['A_Al'] = [np.float32(6.37+0.193)] # +0.205 VESTA, GAS07: 6.37, DR3: 6.41\n",
    "galah_zeropoints['A_Si'] = [np.float32(7.51+0.002)] # VESTA, GAS07: 7.51, DR3: 7.47\n",
    "galah_zeropoints['A_K']  = [np.float32(5.08-0.034)] # VESTA, GAS07: 5.08, DR3: 5.07\n",
    "galah_zeropoints['A_Ca'] = [np.float32(6.31+0.035)] # VESTA, GAS07: 6.31, DR3: 6.18\n",
    "galah_zeropoints['A_Sc'] = [np.float32(3.17-0.016)] # VESTA, GAS07: 3.17, DR3:\n",
    "galah_zeropoints['A_Ti'] = [np.float32(4.90+0.010)] # VESTA, GAS07: 4.90, DR3:\n",
    "galah_zeropoints['A_V']  = [np.float32(4.00-0.116)] # VESTA, GAS07: 4.00, DR3:\n",
    "galah_zeropoints['A_Cr'] = [np.float32(5.64+0.014)] # VESTA, GAS07: 5.64, DR3: 0.132\n",
    "galah_zeropoints['A_Mn'] = [np.float32(5.39+0.097)] # VESTA, GAS07: 5.39, DR3: 0.064\n",
    "galah_zeropoints['A_Co'] = [np.float32(4.92-0.095)] # VESTA, GAS07: 4.92, DR3: 0.072\n",
    "galah_zeropoints['A_Ni'] = [np.float32(6.23-0.005)] # VESTA, GAS07: 6.23, DR3: 6.23\n",
    "galah_zeropoints['A_Cu'] = [np.float32(4.21-0.154)] # VESTA, GAS07: 4.21, DR3: 4.06\n",
    "galah_zeropoints['A_Zn'] = [np.float32(4.60-0.050)] # VESTA, GAS07: 4.60, DR3:\n",
    "galah_zeropoints['A_Rb'] = [np.float32(2.60)] # GAS07: 2.60, DR3: 2.60\n",
    "galah_zeropoints['A_Sr'] = [np.float32(2.92)] # GAS07: 2.92, DR3: 3.30\n",
    "galah_zeropoints['A_Y']  = [np.float32(2.21-0.115)] # VESTA, GAS07: 2.21, DR3: 2.14\n",
    "galah_zeropoints['A_Zr'] = [np.float32(2.58-0.297)] # VESTA, GAS07: 2.58, DR3:\n",
    "galah_zeropoints['A_Mo'] = [np.float32(1.92)] # GAS07: 1.92, DR3:\n",
    "galah_zeropoints['A_Ru'] = [np.float32(1.84)] # GAS07: 1.84, DR3: 2.31\n",
    "galah_zeropoints['A_Ba'] = [np.float32(2.17-0.067)] # VESTA, GAS07: 2.17, DR3: 2.17\n",
    "galah_zeropoints['A_La'] = [np.float32(1.13)] # GAS07: 1.13, DR3:\n",
    "galah_zeropoints['A_Ce'] = [np.float32(1.70)] # GAS07: 1.70, DR3: 2.14\n",
    "galah_zeropoints['A_Nd'] = [np.float32(1.45+0.137)] # VESTA, GAS07: 1.45, DR3:\n",
    "galah_zeropoints['A_Sm'] = [np.float32(1.00+0.130)] # GAS07: 1.00, DR3:\n",
    "galah_zeropoints['A_Eu'] = [np.float32(0.52+0.40)] # GAS07: 0.52, DR3: 0.57\n",
    "galah_zeropoints\n",
    "\n",
    "galah_zeropoints.write('galah_dr4_zeropoints.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3526b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Parameter Biases\n",
    "parameter_biases = dict()\n",
    "\n",
    "parameter_biases['teff']  = 5772.0 - galah_zeropoints['teff'][0]\n",
    "parameter_biases['logg']  = 4.438 - galah_zeropoints['logg'][0] # DR3: offset without non-spectroscopic information\n",
    "parameter_biases['fe_h']  = marcs2014_a_x_sun['Fe'] - galah_zeropoints['A_Fe'][0]  # -0.017 VESTA, GAS07: 7.45, DR3: 7.38\n",
    "parameter_biases['vmic']  = 0.\n",
    "parameter_biases['vsini'] = 0.\n",
    "for element in [\n",
    "    'Li','C','N','O',\n",
    "    'Na','Mg','Al','Si',\n",
    "    'K','Ca','Sc','Ti','V','Cr','Mn','Co','Ni','Cu','Zn',\n",
    "    'Rb','Sr','Y','Zr','Mo','Ru',\n",
    "    'Ba','La','Ce','Nd','Sm','Eu'\n",
    "]:\n",
    "    parameter_biases[element.lower()+'_fe'] = marcs2014_a_x_sun[element] - galah_zeropoints['A_'+element][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b7aeb",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def process_date(parameter_biases, debug = True):\n",
    "    \"\"\"\n",
    "    This function processes all entries of dr60 for a given date\n",
    "    \"\"\"\n",
    "    \n",
    "    final_table = create_final_dr40_table()\n",
    "    \n",
    "    for dr60_index, sobject_id in enumerate(dr60['sobject_id']):\n",
    "        \n",
    "        if dr60_index%250==0:\n",
    "            print(dr60_index, str(np.round(100*dr60_index/len(dr60['sobject_id'])))+'%')\n",
    "        \n",
    "        has_results = False\n",
    "        try:\n",
    "            # Let's import the spectra\n",
    "            spectra = Table.read('../analysis_products/'+str(sobject_id)[:6]+'/'+str(sobject_id)+'/'+str(sobject_id)+'_single_fit_spectrum.fits')\n",
    "            results = Table.read('../analysis_products/'+str(sobject_id)[:6]+'/'+str(sobject_id)+'/'+str(sobject_id)+'_single_fit_results.fits')\n",
    "\n",
    "            has_results = True\n",
    "\n",
    "            # There are completely unreasonable outliers!\n",
    "            if sobject_id in [200714001301248,140303000401330,200714001301055,140313003601295]:\n",
    "                print('Forgetting about '+sobject_id)\n",
    "                has_results = False\n",
    "            \n",
    "        except:\n",
    "            spectra = []\n",
    "            results = []\n",
    "            pass\n",
    "\n",
    "        if has_results:\n",
    "            \n",
    "            final_table['rv'][dr60_index] = results['rv_gauss']\n",
    "            final_table['e_rv'][dr60_index] = results['e_rv_gauss']\n",
    "            \n",
    "            # Populate the stellar parameters and apply parameter bias corrections\n",
    "            for label in ['teff','logg','fe_h','vmic','vsini']:\n",
    "\n",
    "                final_table[label][dr60_index] = results[label]\n",
    "                \n",
    "                # Apply parameter bias corrections\n",
    "                final_table[label][dr60_index] += parameter_biases[label]\n",
    "                \n",
    "                # Populate rescaled uncertainties\n",
    "                final_table['e_'+label][dr60_index] = results['cov_e_'+label]\n",
    "\n",
    "                if label in ['fe_h']:\n",
    "                    final_table['flag_'+label][dr60_index] = results['flag_'+label]\n",
    "\n",
    "            # Save the overall median chi-square for the spectrum\n",
    "            final_table['chi2_sp'][dr60_index] = np.median(np.abs(spectra['sob'] - spectra['smod'])/spectra['uob'])\n",
    "            \n",
    "            # Save the model name of the neural network\n",
    "            final_table['model_name'][dr60_index] = results['model_name'][0]\n",
    "\n",
    "            for element in [\n",
    "                'Li','C','N','O',\n",
    "                'Na','Mg','Al','Si',\n",
    "                'K','Ca','Sc','Ti','V','Cr','Mn','Co','Ni','Cu','Zn',\n",
    "                'Rb','Sr','Y','Zr','Mo','Ru',\n",
    "                'Ba','La','Ce','Nd','Sm','Eu'\n",
    "            ]:\n",
    "                if np.isfinite(results[element.lower()+'_fe']):\n",
    "                    final_table[element.lower()+'_fe'][dr60_index] = results[element.lower()+'_fe'] + parameter_biases[element.lower()+'_fe']\n",
    "                final_table['e_'+element.lower()+'_fe'][dr60_index] = results['cov_e_'+element.lower()+'_fe']\n",
    "                final_table['flag_'+element.lower()+'_fe'][dr60_index] = results['flag_'+element.lower()+'_fe']\n",
    "\n",
    "            # Assess binarity\n",
    "            try:\n",
    "                final_table['sb2_rv_16'][dr60_index],final_table['sb2_rv_50'][dr60_index],final_table['sb2_rv_84'][dr60_index] = assess_binarity(spectra,results,debug)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Assess emission in Halpha/Hbeta\n",
    "            try:\n",
    "                emission_information = assess_emission(spectra, debug=debug)\n",
    "                for key in emission_information.keys():\n",
    "                    if key[:3] == 'ew_':\n",
    "                        final_table[key][dr60_index] = emission_information[key]\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Assess interstellar K absorption\n",
    "            try:\n",
    "                final_table['ew_k_is'][dr60_index],final_table['sigma_k_is'][dr60_index],final_table['rv_k_is'][dr60_index] = assess_interstellar_k_absorption(spectra,debug)\n",
    "                if np.isfinite(final_table['rv_k_is'][dr60_index]):\n",
    "                    final_table['rv_k_is'][dr60_index] += final_table['rv'][dr60_index]\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Assess DIB features\n",
    "            # Using wavelengths from Vogrinčič et al. (2022, in prep.) based on GALAH analyses\n",
    "            for line in [5780.59,5797.19,6613.66]:\n",
    "                \n",
    "                try:\n",
    "                    ew,sigma,rv = assess_dib_absorption(spectra, line, debug)\n",
    "                    final_table['ew_dib'+str(int(line))][dr60_index] = ew\n",
    "                    final_table['sigma_dib'+str(int(line))][dr60_index] = sigma\n",
    "                    if np.isfinite(rv):\n",
    "                        final_table['rv_dib'+str(int(line))][dr60_index] = rv + final_table['rv'][dr60_index]\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            emission_information = [] \n",
    "\n",
    "        final_table['flag_sp'][dr60_index] = apply_final_flag_sp(results,spectra,final_table[dr60_index],has_results,emission_information)\n",
    "        \n",
    "    return(final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0e639b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_table = process_date(parameter_biases,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fin = np.isfinite(final_table['teff'])\n",
    "final_table[is_fin]\n",
    "#[final_table['sobject_id'] == 140307001101272]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089eca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table.write('daily/galah_dr4_allspec_not_validated_'+str(date)+'.fits',overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
