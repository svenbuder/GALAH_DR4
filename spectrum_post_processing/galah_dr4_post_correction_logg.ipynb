{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble \n",
    "try:\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.table import Table, join\n",
    "import astropy.units as u\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.neighbors import KDTree\n",
    "from scipy.interpolate import Akima1DInterpolator,interp1d\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb23a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.argv[1] != '-f':\n",
    "    date = sys.argv[1]\n",
    "else:\n",
    "    date = '131216'\n",
    "    date = '131220' # 47Tuc Globular Cluster\n",
    "#     date = '140824' # Melotte 25 Open Cluster\n",
    "\n",
    "    date = '220516'\n",
    "    date = '220517'\n",
    "#     date = '220708'\n",
    "#     date = '220709'\n",
    "#     date = '220711'\n",
    "    date = '140111'\n",
    "    \n",
    "\n",
    "print('Post-Processing '+date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "galah_raw = Table.read('daily/galah_dr4_allspec_not_validated_'+date+'_single.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "galah_extra = Table.read('../auxiliary_information/dr60_230101_ebv_wise_tmass_gaiadr3corr_xmatch.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "galah_raw_extra = join(galah_raw,galah_extra,keys='sobject_id',join_type='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dffca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(galah_raw_extra['sobject_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327c0f8",
   "metadata": {},
   "source": [
    "# Adjust distances and calculate A(Ks) as well as E(B-V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69830da",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_info = Table()\n",
    "for key in [\n",
    "        'sobject_id','gaiadr3_source_id','teff','logg','fe_h','phot_g_mean_mag','phot_bp_mean_mag','bp_rp',\n",
    "        'h_m','h_msigcom', 'ks_m', 'ks_msigcom', 'W2mag', 'e_W2mag',\n",
    "        'ebv'\n",
    "    ]:\n",
    "        extra_info[key] = galah_raw_extra[key]\n",
    "        \n",
    "key = 'parallax'\n",
    "extra_info[key] = galah_raw_extra[key]\n",
    "extra_info['e_'+key] = galah_raw_extra[key+'_error']\n",
    "extra_info['parallax_gaia_edr3'] = galah_raw_extra[key]\n",
    "extra_info['e_parallax_gaia_edr3'] = galah_raw_extra[key+'_error']\n",
    "\n",
    "extra_info['rv_gaia_dr3'] = galah_raw_extra['radial_velocity']\n",
    "extra_info['e_rv_gaia_dr3'] = galah_raw_extra['radial_velocity_error']\n",
    "extra_info['ruwe_gaia_dr3'] = galah_raw_extra['ruwe']\n",
    "\n",
    "extra_info['r_med'] = 1000. /extra_info['parallax']\n",
    "extra_info['r_lo'] = 1000. /(extra_info['parallax']+extra_info['e_parallax'])\n",
    "extra_info['r_hi'] = 1000. /(extra_info['parallax']-extra_info['e_parallax'])\n",
    "\n",
    "has_r_med_photogeo = np.isfinite(galah_raw_extra['r_med_photogeo'])\n",
    "extra_info['r_med'][has_r_med_photogeo] = galah_raw_extra['r_med_photogeo'][has_r_med_photogeo]\n",
    "extra_info['r_lo'][has_r_med_photogeo] = galah_raw_extra['r_lo_photogeo'][has_r_med_photogeo]\n",
    "extra_info['r_hi'][has_r_med_photogeo] = galah_raw_extra['r_hi_photogeo'][has_r_med_photogeo]\n",
    "\n",
    "has_r_med_geo = np.isnan(galah_raw_extra['r_med_photogeo']) & np.isfinite(galah_raw_extra['r_med_geo'])\n",
    "extra_info['r_med'][has_r_med_geo] = galah_raw_extra['r_med_geo'][has_r_med_geo]\n",
    "extra_info['r_lo'][has_r_med_geo] = galah_raw_extra['r_lo_geo'][has_r_med_geo]\n",
    "extra_info['r_hi'][has_r_med_geo] = galah_raw_extra['r_hi_geo'][has_r_med_geo]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31496dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "galah_raw_extra['tmass_ph_qual'][galah_raw_extra['tmass_ph_qual'].mask] = 'UUU'\n",
    "galah_raw_extra['tmass_ph_qual'][galah_raw_extra['tmass_ph_qual'] == ''] = 'UUU'\n",
    "\n",
    "galah_raw_extra['qph'][galah_raw_extra['qph'].mask] = 'UUUU'\n",
    "galah_raw_extra['qph'][galah_raw_extra['qph'] == ''] = 'UUUU'\n",
    "\n",
    "extra_info['a_ks'] = np.zeros(len(extra_info['sobject_id']))\n",
    "\n",
    "good_h_w2 = np.all([\n",
    "    [x[1] == 'A' for x in galah_raw_extra['tmass_ph_qual']],\n",
    "    [x[1] == 'A' for x in galah_raw_extra['qph']]\n",
    "],axis=0)\n",
    "\n",
    "extra_info['a_ks'][good_h_w2] = (0.918 * (extra_info['h_m'][good_h_w2] - extra_info['W2mag'][good_h_w2] - 0.08)).clip(min=0.00,max=0.50)\n",
    "extra_info['a_ks'][~good_h_w2] = (0.36 * galah_raw_extra['ebv'][~good_h_w2]).clip(min = 0.00, max = 0.50)\n",
    "\n",
    "for index, sobject_id in enumerate(extra_info['sobject_id']):\n",
    "    if sobject_id in [140710008301032,131220004401099,140207004801201]:\n",
    "        if sobject_id == 140710008301032:\n",
    "            extra_info['ks_m'][index] = 1.43 # * u.mag\n",
    "            extra_info['ks_msigcom'][index] = 0.02 # * u.mag\n",
    "        if sobject_id == 131220004401099:\n",
    "            extra_info['ks_m'][index] = 1.46 # * u.mag\n",
    "            extra_info['ks_msigcom'][index] = 0.03 # * u.mag\n",
    "        if sobject_id == 140207004801201:\n",
    "            extra_info['ks_m'][index] = 2.20 # * u.mag\n",
    "            extra_info['ks_msigcom'][index] = 0.01 # * u.mag\n",
    "\n",
    "    if sobject_id in [210115002201239,150210005801171,140710006601104,140709004401117,140708005801203,141102003801353,140710000801284,140709001901194]:\n",
    "\n",
    "        if sobject_id == 210115002201239:\n",
    "            extra_info['ks_m'][index] = 3.28 # * u.mag\n",
    "            extra_info['ks_msigcom'][index] = 0.02 # * u.mag\n",
    "            extra_info['parallax'][index] = 100.0 # * u.mas\n",
    "            extra_info['e_parallax'][index] = 0.1 # * u.mas\n",
    "        if sobject_id == 150210005801171:\n",
    "            extra_info['ks_m'][index] = -3.00 # * u.mag\n",
    "            extra_info['ks_msigcom'][index] = 0.03 # * u.mag\n",
    "            extra_info['parallax'][index] = 88.83 # * u.mas\n",
    "            extra_info['e_parallax'][index] = 0.54 # * u.mas\n",
    "        if sobject_id == 140710006601104:\n",
    "            extra_info['ks_m'][index] = -1.68 # * u.mag\n",
    "            extra_info['ks_msigcom'][index] = 0.05 # * u.mag\n",
    "            extra_info['parallax'][index] = 13.09 # * u.mas\n",
    "            extra_info['e_parallax'][index] = 0.44 # * u.mas\n",
    "        if sobject_id == 140709004401117:\n",
    "            extra_info['ks_m'][index] = -0.16 # * u.mag\n",
    "            extra_info['ks_msigcom'][index] = 0.04 # * u.mag\n",
    "            extra_info['parallax'][index] = 12.62 # * u.mas\n",
    "            extra_info['e_parallax'][index] = 0.18 # * u.mas\n",
    "        if sobject_id == 140708005801203:\n",
    "            extra_info['parallax'][index] = 134.07 # * u.mas\n",
    "            extra_info['e_parallax'][index] = 0.11 # * u.mas\n",
    "        if sobject_id == 141102003801353:\n",
    "            extra_info['ks_m'][index] = -2.84 # * u.mag\n",
    "            extra_info['ks_msigcom'][index] = 0.06 # * u.mag\n",
    "            extra_info['parallax'][index] = 48.94 # * u.mas\n",
    "            extra_info['e_parallax'][index] = 0.77 # * u.mas\n",
    "        if sobject_id == 140710000801284:\n",
    "            extra_info['ks_m'][index] = 2.20 # * u.mag\n",
    "            extra_info['ks_msigcom'][index] = 0.01 # * u.mag\n",
    "            extra_info['parallax'][index] = 9.705958463334975 # * u.mas\n",
    "            extra_info['e_parallax'][index] = 0.15301941 # * u.mas\n",
    "        if sobject_id == 140709001901194:\n",
    "            extra_info['ks_m'][index] = 1.36 # * u.mag\n",
    "            extra_info['ks_msigcom'][index] = 0.02 # * u.mag\n",
    "            extra_info['parallax'][index] = 87.75 # * u.mas\n",
    "            extra_info['e_parallax'][index] = 1.24 # * u.mas  \n",
    "\n",
    "        extra_info['r_med'][index] = 1000. /extra_info['parallax'][index]\n",
    "        extra_info['r_lo'][index] = 1000. /(extra_info['parallax'][index]+extra_info['e_parallax'][index])\n",
    "        extra_info['r_hi'][index] = 1000. /(extra_info['parallax'][index]-extra_info['e_parallax'][index])\n",
    "\n",
    "        extra_info['ebv'][index] = 0.0\n",
    "        extra_info['a_ks'][index] = 0.0\n",
    "\n",
    "    if extra_info['parallax'][index] > 10.:\n",
    "        extra_info['ebv'][index] = 0.0\n",
    "        extra_info['a_ks'][index] = 0.0\n",
    "\n",
    "    if extra_info['a_ks'][index] > 2 * 0.36 * extra_info['ebv'][index]:\n",
    "        extra_info['a_ks'][index] = 0.36 * extra_info['ebv'][index]\n",
    "        \n",
    "    if  extra_info['ebv'][index] > 2 * extra_info['a_ks'][index] / 0.36:\n",
    "        extra_info['ebv'][index] = 2.78 * extra_info['a_ks'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165965f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check entries in open cluster catalog by Cantat-Gaudin et al., 2020, A&A 640, 1\n",
    "cantatgaudin2020_parallaxes = Table.read('../auxiliary_information/CantatGaudin_2020_AandA_640_1.fits')\n",
    "\n",
    "for index, gaiadr3_source_id in enumerate(extra_info['gaiadr3_source_id']):\n",
    "    cantatgaudin2020_match = np.where(gaiadr3_source_id == cantatgaudin2020_parallaxes['GaiaDR2'])[0]\n",
    "    # If there is an entry in this catalog\n",
    "    if len(cantatgaudin2020_match) > 0:\n",
    "        print(cantatgaudin2020_parallaxes['Cluster'][cantatgaudin2020_match[0]])\n",
    "        # replace parallax to be used, if Cantat-Gaudin et al. parallax has smaller uncertainty\n",
    "        if cantatgaudin2020_parallaxes['e_plx'][cantatgaudin2020_match[0]] < extra_info['e_parallax'][index]:\n",
    "            extra_info['parallax'][index] = cantatgaudin2020_parallaxes['plx'][cantatgaudin2020_match[0]]\n",
    "            extra_info['e_parallax'][index] = cantatgaudin2020_parallaxes['e_plx'][cantatgaudin2020_match[0]]\n",
    "            extra_info['r_med'][index] = 1000. /extra_info['parallax'][index]\n",
    "            extra_info['r_lo'][index] = 1000. /(extra_info['parallax'][index]+extra_info['e_parallax'][index])\n",
    "            extra_info['r_hi'][index] = 1000. /(extra_info['parallax'][index]-extra_info['e_parallax'][index])\n",
    "\n",
    "# Check entries in open cluster catalog by Vasiliev & Baumgardt (2021), MNRAS, 505, 5978\n",
    "vasiliev2021_parallaxes = Table.read('../auxiliary_information/VasilievBaumgardt_2021_MNRAS_505_5978_cluster_source_id_memberprob0p7.fits')\n",
    "globular_clusters = Table.read('../auxiliary_information/GlobularClustersGALAHDR4.fits')\n",
    "\n",
    "for index, gaiadr3_source_id in enumerate(extra_info['gaiadr3_source_id']):\n",
    "    vas = dict()\n",
    "    vasiliev2021_match = np.where(gaiadr3_source_id == vasiliev2021_parallaxes['source_id'])[0]\n",
    "    if len(vasiliev2021_match) > 0:\n",
    "        correct_cluster = np.where(globular_clusters['Cluster'] == vasiliev2021_parallaxes['cluster'][vasiliev2021_match[0]])[0]\n",
    "        if len(correct_cluster) > 0:\n",
    "            correct_cluster = globular_clusters[correct_cluster[0]]\n",
    "            vas['parallax_vb21'] = correct_cluster['parallax']\n",
    "            vas['e_parallax_vb21'] = correct_cluster['e_parallax']\n",
    "            vas['r_med_vb21'] = correct_cluster['r_med']\n",
    "            vas['r_lo_vb21'] = correct_cluster['r_lo']\n",
    "            vas['r_hi_vb21'] = correct_cluster['r_hi']\n",
    "        else:\n",
    "            raise ValueError('No extra information for Globular Cluster in auxiliary_information/GlobularClustersGALAHDR4.fits')\n",
    "\n",
    "        if vas['e_parallax_vb21'] < extra_info['e_parallax'][index]:\n",
    "            extra_info['parallax'][index] = vas['parallax_vb21']\n",
    "            extra_info['e_parallax'][index] = vas['e_parallax_vb21']\n",
    "            extra_info['r_med'][index] = vas['r_med_vb21']\n",
    "            extra_info['r_lo'][index] = vas['r_lo_vb21']\n",
    "            extra_info['r_hi'][index] = vas['r_hi_vb21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c27655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in isochrone grid and trained nearest neighbor search machinery 'kdtree'\n",
    "parsec = Table.read('../auxiliary_information/parsec_isochrones/parsec_isochrones_logt_8p00_0p01_10p17_mh_m2p75_0p25_m0p75_mh_m0p60_0p10_0p70_GaiaEDR3_2MASS.fits')\n",
    "# parsec = Table.read('../auxiliary_information/parsec_isochrones/parsec_isochrones_logt_6p19_0p01_10p17_mh_m2p75_0p25_m0p75_mh_m0p60_0p10_0p70_GaiaEDR3_2MASS.fits')\n",
    "# parsec = Table.read('../auxiliary_information/parsec_isochrones/parsec_isochrones_logt_6p19_0p01_10p17_mh_m2p75_0p25_1p00_mh_m0p75_0p05_0p75_GaiaEDR3_2MASS.fits')\n",
    "# file = open('../auxiliary_information/parsec_isochrones/isochrone_kdtree_Teff_logg_M_H.pickle','rb')\n",
    "# parsec_kdtree = pickle.load(file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_age_mass(teff, logg, loglum, m_h, e_teff = 100, e_logg = 0.5, e_loglum = 0.1, e_m_h = 0.2):\n",
    "\n",
    "    e_loglum = e_loglum * loglum\n",
    "    \n",
    "    # Make sure that [Fe/H] stays within parsec grid limits\n",
    "    unique_m_h = np.unique(parsec['m_h'])\n",
    "    if m_h < unique_m_h[0]:\n",
    "        m_h = unique_m_h[0] + 0.001\n",
    "        print('adjust m_h input to ',m_h)\n",
    "    if m_h > unique_m_h[-1]:\n",
    "        m_h = unique_m_h[-1] - 0.001\n",
    "        print('adjust m_h input to ',m_h)\n",
    "        \n",
    "    # Make sure we have at least 2 [Fe/H] dimensions to integrate over\n",
    "    lower_boundary_m_h = np.argmin(np.abs(unique_m_h - (m_h - e_m_h)))\n",
    "    upper_boundary_m_h = np.argmin(np.abs(unique_m_h - (m_h + e_m_h)))\n",
    "    if lower_boundary_m_h == upper_boundary_m_h:\n",
    "        if lower_boundary_m_h == 0:\n",
    "            upper_boundary_m_h = 1\n",
    "        if lower_boundary_m_h == len(unique_m_h)-1:\n",
    "            lower_boundary_m_h = len(unique_m_h)-2\n",
    "    \n",
    "    # find all relevant isochrones points\n",
    "    relevant_isochrone_points = (\n",
    "        (parsec['logT'] > np.log10(teff - e_teff)) & \n",
    "        (parsec['logT'] < np.log10(teff + e_teff)) &\n",
    "        (parsec['logg'] > logg - e_logg) & \n",
    "        (parsec['logg'] < logg + e_logg) &\n",
    "        (parsec['logL'] > loglum - e_loglum) & \n",
    "        (parsec['logL'] < loglum + e_loglum) &\n",
    "        (parsec['m_h']  >= unique_m_h[lower_boundary_m_h]) & \n",
    "        (parsec['m_h']  <= unique_m_h[upper_boundary_m_h])\n",
    "    )\n",
    "    # if len(parsec['logT'][relevant_isochrone_points]) < 10:\n",
    "    #     print('Only '+str(len(parsec['logT'][relevant_isochrone_points]))+' isochrones points available')\n",
    "    \n",
    "    # \n",
    "    model_points = np.array([\n",
    "        10**parsec['logT'][relevant_isochrone_points],\n",
    "        parsec['logg'][relevant_isochrone_points],\n",
    "        parsec['logL'][relevant_isochrone_points],\n",
    "        parsec['m_h'][relevant_isochrone_points]\n",
    "    ]).T\n",
    "    \n",
    "    # find normalising factor\n",
    "    norm = np.log(np.sqrt((2.*np.pi)**4.*np.prod(np.array([e_teff, e_logg, e_loglum ,e_m_h])**2)))\n",
    "    \n",
    "    # sum up lnProb and weight ages/masses by \n",
    "    lnProb = - np.sum(((model_points - [teff, logg, loglum, m_h])/[e_teff, e_logg, e_loglum, e_m_h])**2, axis=1) - norm    \n",
    "    age = np.sum(10**parsec['logAge'][relevant_isochrone_points] * np.exp(lnProb)/10**9)\n",
    "    mass = np.sum(parsec['mass'][relevant_isochrone_points] * np.exp(lnProb))\n",
    "    \n",
    "    # Normalise by probability\n",
    "    Prob_sum = np.sum(np.exp(lnProb))\n",
    "    age /= Prob_sum\n",
    "    mass /= Prob_sum\n",
    "    \n",
    "    return(age, mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a699c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bracket by +/-nn values over (irregular) grid. If idx True, then indices \n",
    "# are returned instead\n",
    "def bracket(inval,grval,nn,idx=False):\n",
    "    \n",
    "    norep = np.sort(np.array(list(dict.fromkeys(list(grval)))))\n",
    "    \n",
    "    x1    = np.where(norep<=inval)\n",
    "    x2    = np.where(norep>inval)\n",
    "    \n",
    "    if idx==False:\n",
    "        lo = norep[x1][-nn::]\n",
    "        up = norep[x2][0:nn]        \n",
    "    else:\n",
    "        lo = x1[0][-nn::]\n",
    "        up = x2[0][0:nn]\n",
    "        \n",
    "    return(lo,up)\n",
    "\n",
    "# linear interpolation for 2 points, Akima for more. Returns nan if \n",
    "# not possible or if extrapolated. The MARCS grid of BC used here is ordered\n",
    "# such that gridt is monotonic. If not, sorting is necessary.\n",
    "def mal(val,gridt,gridbc,dset):\n",
    "    if len(dset[0])>2:\n",
    "        mfun = Akima1DInterpolator(gridt[dset],gridbc[dset])\n",
    "        itp  = mfun(val)\n",
    "    if len(dset[0])==2:\n",
    "        mfun = interp1d(gridt[dset],gridbc[dset],bounds_error=False) \n",
    "        itp  = mfun(val)        \n",
    "    if len(dset[0])<2:\n",
    "        itp = np.nan\n",
    "    return(itp)\n",
    "\n",
    "\n",
    "# read input tables of BCs for several values of E(B-V)\n",
    "files = ['../auxiliary_information/BC_Tables/grid/STcolors_2MASS_GaiaDR2_EDR3_Rv3.1_EBV_0.00.dat']\n",
    "gebv   = [0.0]\n",
    "gri_bc = []\n",
    "\n",
    "kk=0\n",
    "for f in files:\n",
    "\n",
    "    grid = Table.read(f,format='ascii')\n",
    "    if kk==0:\n",
    "        gteff, gfeh, glogg = grid['Teff'],grid['feh'],grid['logg']\n",
    "\n",
    "    bc_g2  = grid['mbol']-grid['G2']\n",
    "    bc_bp2 = grid['mbol']-grid['BP2']\n",
    "    bc_rp2 = grid['mbol']-grid['RP2']\n",
    "\n",
    "    bc_g3  = grid['mbol']-grid['G3']\n",
    "    bc_bp3 = grid['mbol']-grid['BP3']\n",
    "    bc_rp3 = grid['mbol']-grid['RP3']\n",
    "\n",
    "    bc_j   = grid['mbol']-grid['J']\n",
    "    bc_h   = grid['mbol']-grid['H']\n",
    "    bc_k   = grid['mbol']-grid['Ks']\n",
    "\n",
    "    tmp = np.transpose([bc_g2,bc_bp2,bc_rp2,bc_g3,bc_bp3,bc_rp3,bc_j,bc_h,bc_k])\n",
    "    gri_bc.append(tmp)\n",
    "\n",
    "    kk=kk+1\n",
    "\n",
    "gebv   = np.array(gebv)\n",
    "gri_bc = np.array(gri_bc)\n",
    "\n",
    "\n",
    "# compute Bolometric Corrections for stars of known input parameters\n",
    "def bcstar(teff,logg,feh,alpha_fe):\n",
    "    \n",
    "#     teff = np.min([np.max([teff,np.min(grid['Teff'])]),np.max(grid['Teff'])])\n",
    "#     if teff < 3900:\n",
    "#         logg = np.min([np.max([logg,np.min(grid['logg'])]),5.5])\n",
    "#     else:\n",
    "#         logg = np.min([np.max([logg,np.min(grid['logg'])]),5.0])\n",
    "#     feh = np.min([np.max([feh,np.min(grid['feh'])]),np.max(grid['feh'])])\n",
    "    \n",
    "    frange = [8]\n",
    "    flist = ['BC_Ks']\n",
    "    rmi = [8]\n",
    "\n",
    "    itp_bc = np.nan\n",
    "    arr_bc  = np.nan\n",
    "\n",
    "    fold      = [feh]\n",
    "        \n",
    "    # take +/-3 steps in [Fe/H] grid\n",
    "    snip = np.concatenate(bracket(fold,gfeh,3))\n",
    "    itp1 = np.zeros((len(snip)))+np.nan\n",
    "    \n",
    "    for k in range(len(snip)):\n",
    "\n",
    "        x0   = np.where((gfeh==snip[k]) & (np.abs(glogg-logg)<1.1))\n",
    "        lg0  = np.array(list(dict.fromkeys(list(glogg[x0]))))\n",
    "        itp0 = np.zeros((len(lg0)))+np.nan\n",
    "\n",
    "        # at given logg and feh, range of Teff to interpolate across\n",
    "        for j in range(len(lg0)):\n",
    "            ok      = np.where((np.abs(gteff-teff)<1000) & \\\n",
    "                               (gfeh==snip[k]) & (glogg==lg0[j]))\n",
    "\n",
    "            itp0[j] = mal(teff,gteff,gri_bc[0,:,8],ok)\n",
    "\n",
    "        # remove any nan, in case. Either of itp[?,:,:] is enough\n",
    "        k0 = np.where(np.isnan(itp0[:])==False)\n",
    "        # interpolate in logg at correct Teff\n",
    "        itp1[k] = mal(logg,lg0,itp0[:],k0)\n",
    "        \n",
    "    k1  = np.where(np.isnan(itp1[:])==False)\n",
    "    \n",
    "    bc_ks = mal(fold,snip,itp1[:],k1)\n",
    "\n",
    "    if np.isnan(bc_ks):\n",
    "        \n",
    "        bc_grid = np.genfromtxt('../auxiliary_information/BC_Tables/grid/STcolors_2MASS_GaiaDR2_EDR3_Rv3.1_EBV_0.00.dat',names=True)\n",
    "        file = open('../auxiliary_information/BC_Tables/grid/bc_grid_kdtree_ebv_0.00.pickle','rb')\n",
    "        bc_kdtree = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        bc_distance_matches, bc_closest_matches = bc_kdtree.query(np.array([np.log10(teff),logg,feh,alpha_fe]).T,k=8)\n",
    "        bc_ks = np.average(bc_grid['mbol'][bc_closest_matches] - bc_grid['Ks'][bc_closest_matches],weights=bc_distance_matches,axis=-1)\n",
    "        \n",
    "    else:\n",
    "        bc_ks = bc_ks[0]\n",
    "        \n",
    "    return(bc_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b041c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_logg_parallax(teff, logg_in, fe_h, ks_m, ks_msigcom, r_med, r_lo, r_hi, a_ks, e_teff = 100, e_logg = 0.25, e_m_h = 0.2):\n",
    "    \n",
    "    if fe_h < -1:\n",
    "        alpha_fe = 0.4\n",
    "    elif fe_h > 0:\n",
    "        alpha_fe = 0.0\n",
    "    else:\n",
    "        alpha_fe = -0.4 *fe_h\n",
    "    \n",
    "    m_h = fe_h + np.log10(10**alpha_fe * 0.694 + 0.306)\n",
    "    \n",
    "    bc_ks = bcstar(teff, logg_in, fe_h, alpha_fe)\n",
    "    \n",
    "    loglbol = - 0.4 * (ks_m - 5.0*np.log10(r_med/10.) + bc_ks - a_ks - 4.75)#[0]\n",
    "    # Take into account uncertainties of Ks, distance, and adds uncertainties of +- 0.05 mag for A(Ks) and BC(Ks)\n",
    "    loglbol_lo = - 0.4 * (ks_m + ks_msigcom - 5.0*np.log10(r_lo/10.) + (bc_ks + 0.05) - (a_ks - 0.05) - 4.75)#[0]\n",
    "    loglbol_hi = - 0.4 * (ks_m - ks_msigcom - 5.0*np.log10(r_hi/10.) + (bc_ks - 0.05) - (a_ks + 0.05) - 4.75)#[0]\n",
    "    \n",
    "    e_loglum = 0.5*(loglbol_hi-loglbol_lo) / loglbol\n",
    "        \n",
    "    age, mass = calculate_age_mass(teff, logg_in, loglbol, m_h, e_teff, e_logg, e_loglum, e_m_h)\n",
    "    if np.isnan(mass):\n",
    "        age, mass = calculate_age_mass(teff, logg_in, loglbol, m_h, e_teff*2, e_logg*2, e_loglum*2, e_m_h*2)\n",
    "        if np.isnan(mass):\n",
    "            age, mass = calculate_age_mass(teff, logg_in, loglbol, m_h, e_teff*3, e_logg*3, e_loglum*3, e_m_h*3)\n",
    "            if np.isnan(mass):\n",
    "                mass = 1.0\n",
    "                age = np.NaN\n",
    "        \n",
    "    return(4.438 + np.log10(mass) + 4*np.log10(teff/5772.) - loglbol, mass, age, bc_ks, 10**loglbol, loglbol_lo, loglbol_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a222d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_logg_mass_age_bc_ks_lbol(teff, logg_in, fe_h, ks_m, ks_msigcom, r_med, r_lo, r_hi, a_ks):\n",
    "    logg_out, mass, age, bc_ks, lbol, loglbol_lo, loglbol_hi = calculate_logg_parallax(teff, logg_in, fe_h, ks_m, ks_msigcom, r_med, r_lo, r_hi, a_ks)        \n",
    "    iteration = 0\n",
    "    while (abs(logg_out - logg_in) > 0.01) & (iteration < 4):\n",
    "        logg_in = logg_out\n",
    "        logg_out, mass, age, bc_ks, lbol, loglbol_lo, loglbol_hi = calculate_logg_parallax(teff, logg_in, fe_h, ks_m, ks_msigcom, r_med, r_lo, r_hi, a_ks)\n",
    "        iteration += 1\n",
    "    return(mass, age, bc_ks, lbol, logg_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869803cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_info['mass'] = np.zeros(np.shape(extra_info['sobject_id'])[0])\n",
    "extra_info['age'] = np.zeros(np.shape(extra_info['sobject_id'])[0])\n",
    "extra_info['bc_ks'] = np.zeros(np.shape(extra_info['sobject_id'])[0])\n",
    "extra_info['lbol'] = np.zeros(np.shape(extra_info['sobject_id'])[0])\n",
    "extra_info['logg_plx'] = np.zeros(np.shape(extra_info['sobject_id'])[0])\n",
    "for keys in ['mass','age','bc_ks','lbol','logg_plx']:\n",
    "    extra_info[keys][:] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13ad71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "for i in range(len(extra_info['sobject_id'])):\n",
    "    if i%250==0:\n",
    "        print(i,'of',len(extra_info['sobject_id']))\n",
    "        \n",
    "    if np.all(np.isfinite([extra_info['teff'][i],\n",
    "        extra_info['logg'][i], \n",
    "        extra_info['fe_h'][i], \n",
    "        extra_info['ks_m'][i], extra_info['ks_msigcom'][i], \n",
    "        extra_info['r_med'][i], extra_info['r_lo'][i], extra_info['r_hi'][i], \n",
    "        extra_info['a_ks'][i]])\n",
    "    ):\n",
    "        extra_info['mass'][i], extra_info['age'][i], extra_info['bc_ks'][i], extra_info['lbol'][i], extra_info['logg_plx'][i] = iterate_logg_mass_age_bc_ks_lbol(\n",
    "            extra_info['teff'][i], \n",
    "            extra_info['logg'][i],\n",
    "            extra_info['fe_h'][i], \n",
    "            extra_info['ks_m'][i], extra_info['ks_msigcom'][i], \n",
    "            extra_info['r_med'][i], extra_info['r_lo'][i], extra_info['r_hi'][i], \n",
    "            extra_info['a_ks'][i]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f63ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_info.write('daily/galah_dr4_allspec_not_validated_plxlogg_'+date+'.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29685b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
