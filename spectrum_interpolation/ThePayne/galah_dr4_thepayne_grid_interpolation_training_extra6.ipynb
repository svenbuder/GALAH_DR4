{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibility with Python 3\n",
    "from __future__ import (absolute_import, division, print_function)\n",
    "\n",
    "try:\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Basic Tools\n",
    "import numpy as np\n",
    "from astropy.table import Table,vstack\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as op\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# The Payne, see https://github.com/tingyuansen/The_Payne for more details\n",
    "from The_Payne import training\n",
    "from The_Payne import utils\n",
    "from The_Payne import spectral_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b567d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's how we would do it:\n",
    "# training_labels, training_spectra, validation_labels, validation_spectra = utils.load_training_data()\n",
    "\"\"\"\n",
    "Changes that need to be made to training.py in The_Payne if no CUDA is available\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "        \n",
    "if torch.cuda.is_available():\n",
    "    perm = perm.cuda()\n",
    "\"\"\"\n",
    "# That's how we do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose one grid_index\n",
    "try:\n",
    "    grid_index = int(sys.argv[1])\n",
    "    print('Using Grid index ',grid_index)\n",
    "except:\n",
    "    grid_index = 1931\n",
    "    #grid_index = 1259\n",
    "    print('Using default grid index ',grid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = Table.read('../../spectrum_grids/galah_dr4_model_trainingset_gridpoints.fits')\n",
    "\n",
    "teff_logg_feh_name = str(int(grids['teff_subgrid'][grid_index]))+'_'+\"{:.2f}\".format(grids['logg_subgrid'][grid_index])+'_'+\"{:.2f}\".format(grids['fe_h_subgrid'][grid_index])\n",
    "\n",
    "# Let's save our default 7 models\n",
    "seven_grids = np.array([\n",
    "    str(int(grids['teff_subgrid'][grid_index]))+'_'+\"{:.2f}\".format(grids['logg_subgrid'][grid_index])+'_'+\"{:.2f}\".format(grids['fe_h_subgrid'][grid_index]),\n",
    "    str(int(grids['teff_low_subgrid'][grid_index]))+'_'+\"{:.2f}\".format(grids['logg_subgrid'][grid_index])+'_'+\"{:.2f}\".format(grids['fe_h_subgrid'][grid_index]),\n",
    "    str(int(grids['teff_high_subgrid'][grid_index]))+'_'+\"{:.2f}\".format(grids['logg_subgrid'][grid_index])+'_'+\"{:.2f}\".format(grids['fe_h_subgrid'][grid_index]),\n",
    "    str(int(grids['teff_subgrid'][grid_index]))+'_'+\"{:.2f}\".format(grids['logg_low_subgrid'][grid_index])+'_'+\"{:.2f}\".format(grids['fe_h_subgrid'][grid_index]),\n",
    "    str(int(grids['teff_subgrid'][grid_index]))+'_'+\"{:.2f}\".format(grids['logg_high_subgrid'][grid_index])+'_'+\"{:.2f}\".format(grids['fe_h_subgrid'][grid_index]),\n",
    "    str(int(grids['teff_subgrid'][grid_index]))+'_'+\"{:.2f}\".format(grids['logg_subgrid'][grid_index])+'_'+\"{:.2f}\".format(grids['fe_h_low_subgrid'][grid_index]),\n",
    "    str(int(grids['teff_subgrid'][grid_index]))+'_'+\"{:.2f}\".format(grids['logg_subgrid'][grid_index])+'_'+\"{:.2f}\".format(grids['fe_h_high_subgrid'][grid_index])   \n",
    "])\n",
    "\n",
    "# Not all of the default models have to exist (e.g. for logg == 5.0)\n",
    "# In that case, replace them with the middle grid to give more weight to it.\n",
    "\n",
    "for seven_grid_index in range(len(seven_grids)):\n",
    "    try:\n",
    "        training_set = Table.read('../training_input/'+seven_grids[seven_grid_index]+'/galah_dr4_trainingset_'+seven_grids[seven_grid_index]+'_incl_vsini.fits')\n",
    "    except:\n",
    "        print('No grid available for '+seven_grids[seven_grid_index]+', replacing with '+str(int(grids['teff_subgrid'][grid_index]))+'_'+\"{:.2f}\".format(grids['logg_subgrid'][grid_index])+'_'+\"{:.2f}\".format(grids['fe_h_subgrid'][grid_index]))\n",
    "        seven_grids[seven_grid_index] = str(int(grids['teff_subgrid'][grid_index]))+'_'+\"{:.2f}\".format(grids['logg_subgrid'][grid_index])+'_'+\"{:.2f}\".format(grids['fe_h_subgrid'][grid_index])\n",
    "\n",
    "print(seven_grids)\n",
    "\n",
    "training_labels = []\n",
    "training_set_flux = []\n",
    "\n",
    "wavelength_file = '../training_input/galah_dr4_3dbin_wavelength_array.pickle'\n",
    "wavelength_file_opener = open(wavelength_file,'rb')\n",
    "wavelength_array = pickle.load(wavelength_file_opener)\n",
    "wavelength_file_opener.close()\n",
    "\n",
    "for seven_teff_logg_feh_name in seven_grids:\n",
    "    training_set_one = Table.read('../training_input/'+seven_teff_logg_feh_name+'/galah_dr4_trainingset_'+seven_teff_logg_feh_name+'_incl_vsini.fits')\n",
    "    \n",
    "    labels = tuple(training_set.keys()[2:-1])\n",
    "\n",
    "    training_labels.append(np.array([training_set_one[label] for label in labels]).T)\n",
    "\n",
    "    masks = Table.read('../training_input/'+seven_teff_logg_feh_name+'/'+seven_teff_logg_feh_name+'_masks.fits')\n",
    "    \n",
    "    flux_ivar_file = '../training_input/'+seven_teff_logg_feh_name+'/galah_dr4_trainingset_'+seven_teff_logg_feh_name+'_incl_vsini_flux_ivar.pickle'\n",
    "    flux_ivar_file_opener = open(flux_ivar_file,'rb')\n",
    "    training_set_flux.append(pickle.load(flux_ivar_file_opener))\n",
    "    flux_ivar_file_opener.close()\n",
    "\n",
    "training_labels = np.concatenate((training_labels))\n",
    "training_set_flux = np.concatenate((training_set_flux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tuple(training_set.keys()[2:-1])\n",
    "\n",
    "print('Labels to be fitted: ',len(labels))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10566b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'galah_dr4_thepayne_model_extra6_'+teff_logg_feh_name+'_'+str(len(labels))+'labels'\n",
    "\n",
    "print('Will create The Payne model to be stored at ')\n",
    "print('models/'+model_file+'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab13a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We will split the data set into 90% training set and 10% validation set\n",
    "# To allow to reproduce that, we will use a reproducable random_state computed from teff/logg/fe_h\n",
    "train, test = train_test_split(np.arange(np.shape(training_set_flux)[0]), test_size=0.1, random_state=int(grids['teff_subgrid'][grid_index])+int(10*grids['logg_subgrid'][grid_index])+int(100*grids['fe_h_subgrid'][grid_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9bdd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.neural_net(\n",
    "    training_labels = training_labels[train,:], \n",
    "    training_spectra = training_set_flux[train,:],\n",
    "    validation_labels = training_labels[test,:], \n",
    "    validation_spectra = training_set_flux[test,:],\n",
    "    num_neurons=300,\n",
    "    learning_rate=1e-4,\n",
    "    num_steps=1e4,\n",
    "    batch_size=128,#np.min([256,np.int(np.shape(training_labels)[1]/2.)]), \n",
    "    num_pixel=np.shape(training_set_flux[0])[0],\n",
    "    training_loss_name = 'loss_functions/'+model_file+'_loss.npz',\n",
    "    payne_model_name = 'models/'+model_file+'.npz'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a776dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.load('loss_functions/'+model_file+'_loss.npz') # the output array also stores the training and validation loss\n",
    "training_loss = tmp[\"training_loss\"]\n",
    "validation_loss = tmp[\"validation_loss\"]\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(np.arange(training_loss.size)*100, training_loss, 'k', lw=0.5, label = 'Training set')\n",
    "plt.plot(np.arange(training_loss.size)*100, validation_loss, 'r', lw=0.5, label = 'Validation set')\n",
    "plt.legend(loc = 'best', frameon = False, fontsize= 18)\n",
    "plt.yscale('log')\n",
    "#plt.ylim([5,100])\n",
    "plt.xlabel(\"Step\", size=20)\n",
    "plt.ylabel(\"Loss\", size=20)\n",
    "plt.savefig('loss_functions/'+model_file+'_loss.png',dpi=200,bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.load('models/'+model_file+'.npz')\n",
    "w_array_0 = tmp[\"w_array_0\"]\n",
    "w_array_1 = tmp[\"w_array_1\"]\n",
    "w_array_2 = tmp[\"w_array_2\"]\n",
    "b_array_0 = tmp[\"b_array_0\"]\n",
    "b_array_1 = tmp[\"b_array_1\"]\n",
    "b_array_2 = tmp[\"b_array_2\"]\n",
    "x_min = tmp[\"x_min\"]\n",
    "x_max = tmp[\"x_max\"]\n",
    "tmp.close()\n",
    "NN_coeffs = (w_array_0, w_array_1, w_array_2, b_array_0, b_array_1, b_array_2, x_min, x_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58358065",
   "metadata": {},
   "source": [
    "# For validation purposes, we can recreate some training spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89775da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d578b2a",
   "metadata": {
    "code_folding": [
     0,
     27,
     124
    ]
   },
   "outputs": [],
   "source": [
    "def load_dr3_lines(mode_dr3_path = '../../spectrum_analysis/spectrum_masks/important_lines'):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    important_lines = [\n",
    "        [4861.3230,r'H$_\\beta$',r'H$_\\beta$'],\n",
    "        [6562.7970,r'H$_\\alpha$',r'H$_\\alpha$']\n",
    "    ]\n",
    "    \n",
    "    important_molecules = [\n",
    "        [4710,4740,'Mol. C2','Mol. C2'],\n",
    "        [7594,7695,'Mol. O2 (tell.)','Mol. O2 (tell.)']\n",
    "        ]\n",
    "\n",
    "    print('Trying to read in list of elements run as part of DR3')\n",
    "    line, wave = np.loadtxt(mode_dr3_path,usecols=(0,1),unpack=True,dtype=str, comments=';')\n",
    "\n",
    "    for each_index in range(len(line)):\n",
    "        if line[each_index] != 'Sp':\n",
    "            if len(line[each_index]) < 5:\n",
    "                important_lines.append([float(wave[each_index]), line[each_index], line[each_index]])\n",
    "            else:\n",
    "                important_lines.append([float(wave[each_index]), line[each_index][:-4], line[each_index]])\n",
    "    print('Success')\n",
    "        \n",
    "    return(important_lines,important_molecules)\n",
    "\n",
    "def plot_spectrum(wave,flux,flux_uncertainty,title_text):\n",
    "    \"\"\"\n",
    "    Let's plot a spectrum, that is, flux over wavelenth\n",
    "    \n",
    "    We will plot 12 different subplot ranges (3 for each CCD) to allow better assessment of the results\n",
    "    \n",
    "    INPUT:\n",
    "    wave : 1D-array with N pixels\n",
    "    flux : 1D-array with N pixels or (M,N)-array with N pixels for M spectra (e.g. M = 2 for observed and synthetic spectrum)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Let's define the wavelength beginnings and ends for each suplot\n",
    "    subplot_wavelengths = np.array([\n",
    "        [4700,4775],\n",
    "        [4770,4850],\n",
    "        [4840,4900],\n",
    "        [5600,5730],\n",
    "        [5720,5805],\n",
    "        [5795,6000],\n",
    "        [6400,6600],\n",
    "        [6590,6670],\n",
    "        [6660,6739],\n",
    "        [7600,7720],\n",
    "        [7710,7820],\n",
    "        [7810,7900]\n",
    "    ])\n",
    "    \n",
    "    # How many subplots will we need?\n",
    "    nr_subplots = np.shape(subplot_wavelengths)[0]\n",
    "    \n",
    "    f, gs = plt.subplots(nr_subplots,1,figsize=(8.3,11.7),sharey=True)\n",
    "    \n",
    "    try:\n",
    "        # test if several spectra fed into flux\n",
    "        dummy = np.shape(flux)[1] == len(wave)\n",
    "        flux_array_indices = np.shape(flux)[0]\n",
    "        flux = np.array(flux)\n",
    "    except:\n",
    "        flux_array_indices = 1\n",
    "\n",
    "    # Let's loop over the subplots\n",
    "    for subplot in range(nr_subplots):\n",
    "        \n",
    "        # Which part of the observed/model spectrum is in our subplot wavelength range?\n",
    "        in_subplot_wavelength_range = (wave > subplot_wavelengths[subplot,0]) & (wave < subplot_wavelengths[subplot,1])\n",
    "\n",
    "        ax = gs[subplot]\n",
    "        \n",
    "        # if only 1 spectrum\n",
    "        if flux_array_indices == 1:\n",
    "            ax.plot(wave[in_subplot_wavelength_range],flux[in_subplot_wavelength_range],lw=0.5);\n",
    "        else:\n",
    "            for index in range(flux_array_indices):\n",
    "                if index == 0:\n",
    "                    ax.plot(wave[in_subplot_wavelength_range],flux[0,in_subplot_wavelength_range],lw=0.5,c='k',label='data');\n",
    "                    ax.plot(wave[in_subplot_wavelength_range],1.05 + flux_uncertainty[in_subplot_wavelength_range],lw=0.5,c='C3',label='scatter');\n",
    "                if index == 1:\n",
    "                    ax.plot(wave[in_subplot_wavelength_range],flux[index,in_subplot_wavelength_range],lw=0.5,c='C0',label='model (initial)');\n",
    "                    ax.plot(wave[in_subplot_wavelength_range],1.05 + np.abs(flux[0,in_subplot_wavelength_range]-flux[index,in_subplot_wavelength_range]),lw=0.5,c='C4',label='residuals');\n",
    "            if subplot == nr_subplots-1:\n",
    "                ax.legend(ncol=2,loc='lower right',fontsize=6)\n",
    "                \n",
    "        maski = 0\n",
    "        for (mask_beginning, mask_end) in zip(masks['mask_begin'],masks['mask_end']):\n",
    "            if (mask_beginning > wave[in_subplot_wavelength_range][0]) & (mask_end < wave[in_subplot_wavelength_range][-1]):\n",
    "                if maski == 0:\n",
    "                    ax.axvspan(mask_beginning,mask_end,color='C0',alpha=0.1,label='Mask')\n",
    "                    maski += 1\n",
    "                else:\n",
    "                    ax.axvspan(mask_beginning,mask_end,color='C0',alpha=0.1)\n",
    "        each_index = 0 \n",
    "        for each_element in important_lines:\n",
    "            if (each_element[0] > subplot_wavelengths[subplot,0]) & (each_element[0] < subplot_wavelengths[subplot,1]):\n",
    "            \n",
    "                offset = -0.05+0.1*(each_index%3)\n",
    "                each_index+=1\n",
    "                ax.axvline(each_element[0],lw=0.2,ls='dashed',c='r')\n",
    "                if each_element[1] in ['Li','C','O']:\n",
    "                    ax.text(each_element[0],offset,each_element[1],fontsize=10,ha='center',color='pink')\n",
    "                elif each_element[1] in ['Mg','Si','Ca','Ti','Ti2']:\n",
    "                    ax.text(each_element[0],offset,each_element[1],fontsize=10,ha='center',color='b')\n",
    "                elif each_element[1] in ['Na','Al','K']:\n",
    "                    ax.text(each_element[0],offset,each_element[1],fontsize=10,ha='center',color='orange')\n",
    "                elif each_element[1] in ['Sc','V', 'Cr','Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn']:\n",
    "                    ax.text(each_element[0],offset,each_element[1],fontsize=10,ha='center',color='brown')\n",
    "                elif each_element[1] in ['Rb', 'Sr', 'Y', 'Zr', 'Ba', 'La', 'Ce','Mo','Ru', 'Nd', 'Sm','Eu']:\n",
    "                    ax.text(each_element[0],offset,each_element[1],fontsize=10,ha='center',color='purple')\n",
    "        ax.set_ylim(-0.1,1.2)\n",
    "        if subplot == 11:\n",
    "            ax.set_xlabel(r'Wavelength / $\\mathrm{\\AA}$')\n",
    "        ax.axhline(1.05,lw=0.5,color='k')\n",
    "        ax.set_ylabel('Flux / norm.')\n",
    "    f.suptitle(title_text)\n",
    "    plt.tight_layout(h_pad=0)\n",
    "    \n",
    "    return f\n",
    "\n",
    "def plot_validation_spectra(index):\n",
    "    \n",
    "    default_labels = (training_labels[index]-x_min)/(x_max-x_min) - 0.5\n",
    "\n",
    "    default_model = spectral_model.get_spectrum_from_neural_net(scaled_labels = default_labels, NN_coeffs = NN_coeffs)\n",
    "\n",
    "    f = plot_spectrum(\n",
    "        wavelength_array,\n",
    "        [training_set_flux[index],default_model],\n",
    "        np.zeros(len(default_model)),\n",
    "        str(index)+': '+\n",
    "        'Teff='+str(int(np.round(training_labels[index,0])))+'K, '+\n",
    "        'logg='+str(np.round(training_labels[index,1],decimals=2))+', '+\n",
    "        '[Fe/H]='+str(np.round(training_labels[index,2],decimals=2))+', '+\n",
    "        'vmic='+str(np.round(training_labels[index,3],decimals=2))+'km/s, '+\n",
    "        'vsini='+str(np.round(training_labels[index,4],decimals=1))+'km/s'\n",
    "    )\n",
    "    f.savefig('validation_spectra/ThePayne_Spectrum_Grid'+str(grid_index)+'_'+str(index)+'.pdf',bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353fdf65",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if plot_validation:\n",
    "    \n",
    "    # Load some important lines\n",
    "    important_lines, important_molecules = load_dr3_lines()\n",
    "\n",
    "    # Load Spectrum masks\n",
    "    masks = Table.read('../../spectrum_analysis/spectrum_masks/solar_spectrum_mask.fits')\n",
    "\n",
    "    for index in range(37):\n",
    "        plot_validation_spectra(index)\n",
    "\n",
    "    for index in np.arange(50,1700,50):\n",
    "        plot_validation_spectra(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3016c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
